{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to get \"/ListSensors\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 21:47:08,741 - INFO - Starting main process\n",
      "Starting main process\n",
      "2024-09-03 21:47:08,742 - INFO - Using provided API key\n",
      "Using provided API key\n",
      "2024-09-03 21:47:08,742 - INFO - Initiating API request to fetch sensor data\n",
      "Initiating API request to fetch sensor data\n",
      "2024-09-03 21:47:08,742 - INFO - Attempt 1 to fetch data\n",
      "Attempt 1 to fetch data\n",
      "2024-09-03 21:47:18,818 - WARNING - Request timed out. Retrying... (Elapsed time: 10.08s)\n",
      "Request timed out. Retrying... (Elapsed time: 10.08s)\n",
      "2024-09-03 21:47:19,826 - INFO - Attempt 2 to fetch data\n",
      "Attempt 2 to fetch data\n",
      "2024-09-03 21:47:29,931 - WARNING - Request timed out. Retrying... (Elapsed time: 21.19s)\n",
      "Request timed out. Retrying... (Elapsed time: 21.19s)\n",
      "2024-09-03 21:47:30,939 - INFO - Attempt 3 to fetch data\n",
      "Attempt 3 to fetch data\n",
      "2024-09-03 21:47:41,008 - ERROR - API request timed out after 30 seconds\n",
      "API request timed out after 30 seconds\n",
      "2024-09-03 21:47:41,025 - ERROR - Your BreatheLondon API Limit exceeded\n",
      "Your BreatheLondon API Limit exceeded\n",
      "2024-09-03 21:47:41,028 - ERROR - Failed to fetch data. Please check your API key and try again later.\n",
      "Failed to fetch data. Please check your API key and try again later.\n"
     ]
    }
   ],
   "source": [
    "from breathe_london_api_list_sensors import main, logger\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "df, site_codes, output_file = main(\n",
    "    api_key=os.getenv(\"API_KEY\"), output_file=\"my_output.csv\", site_code_limit=10\n",
    ")\n",
    "\n",
    "if df is None:\n",
    "    logger.error(\"Failed to fetch data. Please check your API key and try again later.\")\n",
    "else:\n",
    "    logger.info(f\"Data saved to: {output_file}\")\n",
    "    logger.info(f\"First few site codes: {site_codes[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to hourly \"/getClarityData\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('API_KEY')  # Replace with your actual API key\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "today = pd.Timestamp.today().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "API_CLARITY_HOURLY_URL = \"https://api.breathelondon.org/api/getClarityData/{siteCode}/{species}/{startTime}/{endTime}/{averaging}?key={apiKey}\"\n",
    "\n",
    "def get_clarity_data(siteCode, species, startTime, endTime, averaging):\n",
    "    try:\n",
    "    # Format the API URL with required parameters\n",
    "        formatted_startTime = startTime.replace(\" \", \"%20\")\n",
    "        formatted_endTime = endTime.replace(\" \", \"%20\")\n",
    "        url = API_CLARITY_HOURLY_URL.format(siteCode=siteCode, species=species, startTime=formatted_startTime, endTime=formatted_endTime, averaging=averaging, apiKey=API_KEY)\n",
    "    \n",
    "        response = requests.get(url)\n",
    "    \n",
    "        # Check if request was successful\n",
    "        if response.status_code == 200:\n",
    "            sensors = response.json()\n",
    "            sensors = pd.DataFrame.from_dict(sensors)\n",
    "            return sensors\n",
    "        else:\n",
    "            print(f\"Error with status code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"Received an unexpected response:\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Add sitecodes needed here\n",
    "siteCodes = [\"CLDP0001\", \"CLDP0002\"]  \n",
    "species1 = \"IPM25\"\n",
    "species2 = \"INO2\"\n",
    "averaging = \"Hourly\"\n",
    "\n",
    "# Calculate start and end times\n",
    "endTime = datetime.now()  # Current time\n",
    "startTime = endTime - timedelta(days=365)  # One month before current time\n",
    "\n",
    "# Convert datetime objects to strings\n",
    "endTime_str = endTime.strftime(\"%a %d %b %Y %H:%M:%S\")\n",
    "startTime_str = startTime.strftime(\"%a %d %b %Y %H:%M:%S\")\n",
    "\n",
    "df_list = []  # List to store data for each site code\n",
    "\n",
    "for siteCode in siteCodes:\n",
    "    # Get data for first species\n",
    "    data1 = get_clarity_data(siteCode, species1, startTime_str, endTime_str, averaging)\n",
    "    if data1 is not None and isinstance(data1, pd.DataFrame):\n",
    "        print(f\"Received data for {siteCode} and {species1}\")\n",
    "        data1['DateTime'] = pd.to_datetime(data1['DateTime'])\n",
    "        data1['mod_datetime'] = data1['DateTime'] + pd.Timedelta(hours=1)\n",
    "        data1['species'] = species1\n",
    "        df_list.append(data1)  # Add the DataFrame to the list\n",
    "    else:\n",
    "        print(f\"No data received for {siteCode} and {species1}\")\n",
    "\n",
    "    # Get data for second species\n",
    "    data2 = get_clarity_data(siteCode, species2, startTime_str, endTime_str, averaging)\n",
    "    if data2 is not None and isinstance(data2, pd.DataFrame):\n",
    "        print(f\"Received data for {siteCode} and {species2}\")\n",
    "        data2['DateTime'] = pd.to_datetime(data2['DateTime'])\n",
    "        data2['mod_datetime'] = data2['DateTime'] + pd.Timedelta(hours=1)\n",
    "        data2['species'] = species2\n",
    "        df_list.append(data2)  # Add the DataFrame to the list\n",
    "    else:\n",
    "        print(f\"No data received for {siteCode} and {species2}\")\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "if df_list:\n",
    "    df_all = pd.concat(df_list)\n",
    "    # print(df.head())\n",
    "else:\n",
    "    print(\"No data received for all site codes and species.\")\n",
    "\n",
    "print(df_all.mod_datetime.max()), print(df_all.SiteCode.nunique(),print(df_all.shape))\n",
    "df_all.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breathe-london-api-qeieqM5a-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
